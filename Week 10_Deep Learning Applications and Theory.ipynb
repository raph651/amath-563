{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Auto)Encoders - Decoders\n",
    "\n",
    "Input $\\xrightarrow{Encoder}$ Latent $\\xrightarrow{Decoder}$ Ouput, Latent represents our hidden layers (bottleneck layer). This process is the same as feature extraction and reconstruction.\n",
    "\n",
    "* Map high-dimensional data to low dimensions\n",
    "    - Visualization\n",
    "    - Embedding\n",
    "* Compression\n",
    "* Learn Latent Features\n",
    "* Unsupervised\n",
    "\n",
    "* Few examples: seq2seq (RNN), Variational AE, Linear AE - PCA\n",
    "\n",
    "Clustering Human Movemennts - Decoder states, Weak training contraction in embeeding space\n",
    "\n",
    "Concatenate Encoder and Decoder State to get $S$ State\n",
    "\n",
    "Concatenate $K$ sequences (for RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders vs Classical  Decompositions\n",
    "\n",
    "* Autoencoders learned a fixed-sized representation (dimension is a hyperparameter )\n",
    "* Autoencoder is **nonlinear** and **learned iteratively**\n",
    "* Latene space non necessarily orthogonal (unlike POD)\n",
    "<div class=\"verticalhorizontal\">\n",
    "    <img src=\"images/10_1.png\" width =\"650\" height=\"550\" alt=\"centered image\" />\n",
    "</div>* Architecture choice is flexible: FC, CNN, RNN\n",
    "* Encoder and Decoder could be of different types\n",
    "* Directions can encode particular features in the data\n",
    "\n",
    "**Clustering in Latent Space**\n",
    "* Projection onto the latent space can yield clusters\n",
    "* Since unordered, you may need to take decomposition of latent space to visualize\n",
    "* GANs, manipulate latent space to get desired features\n",
    "\n",
    "**Latent Space as a Distribution**\n",
    "* Latent Space of VAEs learn the mean and standard deviation of a multi-dimensional Gaussian\n",
    "* Loss function uses KL divergence in addition to MSE reconstruction loss\n",
    "\n",
    "**KL Divergence for VAE**\n",
    "* Encoder generates a probability distribution $Q(z)$ as a function of input $X$ (represents $z$ most likely to produce $X$)\n",
    "* Decoder generates conditional probability $P(X|z)$<br>\n",
    "$\\mathcal{D}[Q(z)]||P(z|X)=E_{z\\sim Q}[logQ(z) -log P(z|X)]$\n",
    "* For Gaussian $Q, KL$ divergence becomes: <br>\n",
    "$\\mathcal{D}[\\mathcal{N}(\\mu (X), \\Sigma (X))||\\mathcal{N}(0,I)]=\\frac{1}{2}(tr(\\Sigma (X))+(\\mu (X))^T(\\mu (X)) -k - log det(\\Sigma (X)) ) $\n",
    "\n",
    "* Mixed Losses: MSE and KL Divergence. Penalizing reconstruction loss encourages distribution (deviated from the prior) to describe the input. Penalizing KL divergence attracts distribution to have 0 mean. Without regularization, the distribution can \"cheat\" by learning narrow distributions.\n",
    "\n",
    "* VAEs: beta-VAE, Deep Feature Consistent VAE, DIP VAE\n",
    "\n",
    "<div class=\"verticalhorizontal\">\n",
    "    <img src=\"images/10_2.png\" width =\"550\" height=\"450\" alt=\"centered image\" />\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": false,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
