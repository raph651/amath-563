{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of Brain Networks and Learninng\n",
    "\n",
    "1. Neurons: simple comptational units\n",
    "2. Well connected\n",
    "3. Parallelism and Recurrence\n",
    "4. Hierarchically structured\n",
    "5. Learning\n",
    " 1. Features\n",
    " 2. Changing connections\n",
    "\n",
    "### 1. Neurons: simple conputational units\n",
    "Firing rate -> $\\displaystyle \\frac{df}{dt}=-f+tanh(x(t))$\n",
    "\n",
    "<img src=\"images/2022-03-29-15-17-28.png\" width =\"500\" height=\"350\"/>\n",
    "\n",
    "### Perceptron\n",
    "$$f(x)=\\begin{cases}\n",
    "1 & \\text{if } w \\cdot x+b >0 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "\n",
    "Network trains its weights based on $\\textbf{labeled training}$ data, i.e. optimizes $\\textbf{cost}$ function between expected outputs and actual outputs\n",
    "\n",
    "### 2. Well Connected \n",
    "Human Brain - $10^{11}$ neurons, $10^{14}$ connections (synapses)\n",
    "\n",
    "Connectome - connection map (eg. diagonal connection - locally connected)\n",
    "\n",
    "### 3. Parallelism (flow structure)\n",
    "Computations done on various scales\n",
    "\n",
    "Many recurrences\n",
    "\n",
    "### 4. Hierarchical Layered Structure \n",
    "- Layers \n",
    "- Columns \n",
    "- Defined Flow\n",
    "- Functional Organization\n",
    "- Feedback\n",
    "\n",
    "**Deep Neural Networks - Forward Propagation**:\n",
    "- Multiple layers of **simple units** \n",
    "- Each unit computes a **weighted sum** of its inputs\n",
    "- Weighted Sum is passed through a **nonlinear** function\n",
    "- the learning algorithm changes the **weights**\n",
    "\n",
    "### Convolutional Nets (CNNS)\n",
    "Examine different patchs of inputs, and return to hidden layers.\n",
    "\n",
    "Example: LeNet 5 (Handwriting recognition)\n",
    "\n",
    "<img src=\"images/1_2.png\" width =\"500\" height=\"350\"/>\n",
    "\n",
    "### 5. Learning\n",
    "#### 5.1 Feature Extraction\n",
    "- Classification/Recognition\n",
    "- Regression Direct\n",
    "- Regression Indirect\n",
    "#### 5.2 Synaptic Plasticity\n",
    "- Adaptive connections\n",
    "- The \"strength\" of synapses changes\n",
    "\n",
    "**Supervised Learning, Back Propagation, Unsupervised Learning, Reinforcement Learning**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks Fundamentals\n",
    "### 1. Single Neuron\n",
    "- integration $\\displaystyle \\sum_{i=1}^n x_iw_i+b $\n",
    "- activation $\\displaystyle f(\\sum_{i=1}^n x_iw_i+b)$\n",
    "- input to other neurons $y=f(\\sum_{i=1}^n x_iw_i+b)$\n",
    "\n",
    "#### Activation\n",
    "- linear\n",
    "- step\n",
    "- sigmoid $\\displaystyle f=\\frac{1}{1+e^{-x}}$\n",
    "- tanh\n",
    "- ReLU (Rectified Linear Unit) $\\;\\displaystyle f=\\text{max}(x,0)$\n",
    "- Leaky (parametric) ReLU $\\;\\displaystyle f=\\text{max}(x,ax)$\n",
    "- Maxout $\\;\\displaystyle f=\\text{max}(w_1^Tx+b_1,w_2^Tx+b2) ,\\;k=2$\n",
    "\n",
    "### 2. Connecting Neurons\n",
    "<img src=\"images/1_5.png\" width =\"500\" height=\"350\"/>\n",
    "\n",
    "- Recurrent\n",
    "- Gates\n",
    "- Layered\n",
    "- Local Layered\n",
    "\n",
    "#### Universal Approximation\n",
    "Input and output layer are required. But how many units and layers do we need for the hidden layers? How to deal with recurrence?\n",
    "\n",
    "### 3. Flow/Pathways/Layers\n",
    "\n",
    "Flow can be forward or backward. (RNNS handles with recurrence by unfolding them)\n",
    "\n",
    "Three Pillars to consider: plausibility, optimality, and efficiency.\n",
    "\n",
    "### 4. Learning\n",
    "- Supervised Learning: cost function, labeled data\n",
    "- Unsupervised Learning: generative learning, latent representation\n",
    "- Reinforcement Learning: rewards, optimization through control\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42bb6a2c1686de5e1e448fe975e26b056eae8a02500337bf312c2103fe0e4268"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": false,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
